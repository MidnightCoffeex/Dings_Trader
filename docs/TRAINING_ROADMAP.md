# Dings-Trader ML Training Roadmap

## ðŸŽ¯ Workflow & Prozess

Dieses Dokument beschreibt den Training-Prozess fÃ¼r das dings-trader ML-System.

### Sub-Agent Architektur

Wir arbeiten mit einem **2-Ebenen-Agentensystem**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAIN AGENT (Dings) - Orchestrator      â”‚
â”‚  â€¢ Steuert den Gesamtprozess            â”‚
â”‚  â€¢ Koordiniert Sub-Agents               â”‚
â”‚  â€¢ Integriert Ergebnisse                â”‚
â”‚  â€¢ Browser-Automation fÃ¼r Colab         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ spawns
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SUB-AGENTS (je nach Aufgabe)                    â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Codex CLI       â”‚  â”‚ Gemini CLI           â”‚  â”‚  (aktuell deaktiviert: quota/keine Nutzung)
â”‚  â”‚ gpt-5.2/5.3     â”‚  â”‚ gemini-3-pro-preview â”‚  â”‚
â”‚  â”‚ â€¢ Coding        â”‚  â”‚ â€¢ Analysis           â”‚  â”‚
â”‚  â”‚ â€¢ Algorithms    â”‚  â”‚ â€¢ Architecture       â”‚  â”‚
â”‚  â”‚ â€¢ Notebooks     â”‚  â”‚ â€¢ Documentation      â”‚  â”‚
â”‚  â”‚ â€¢ Full-auto     â”‚  â”‚ â€¢ Reasoning          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow fÃ¼r Sub-Agents

**FÃ¼r Sub-Agent (Coding/Implementation):**
> Modelle: `gpt-5.2-codex`, `gpt-5.3-codex`, `gemini-3-pro-preview`, `gemini-3-flash-preview`:
> Du bist ein Sub-Agent. Deine Aufgabe ist es, Code lokal im Workspace zu schreiben.
> - Arbeite in `/home/maxim/.openclaw/workspace/projects/dings-trader/TraderHimSelf/`
> - Lese `/home/maxim/.openclaw/workspace/projects/dings-trader/PLAN.md`
> - Schreibe modularen, gut kommentierten Code
> - FÃ¼r Colab: Erstelle `.ipynb` Dateien (wir kopieren sie spÃ¤ter manuell)
> - Speichere alle Zwischenergebnisse
> - Keine externen API-Aufrufe ohne Erlaubnis
> - Fertige Tasks/zwischen Tasks berichten


**FÃ¼r Sub-Agent (Analysis/Design):**
> Modelle: `gpt-5.2-codex`, `gpt-5.3-codex`, `gemini-3-pro-preview`, `gemini-3-flash-preview`:
> Du bist ein Sub-Agent. Deine Aufgabe ist es, Analyse und Design zu liefern.
> - Arbeite lokal im `/home/maxim/.openclaw/workspace/projects/dings-trader/TraderHimSelf/` 
> - Analysiere Daten, entwerfe Architekturen, schreibe Dokumentation
> - Speichere Ergebnisse als Dateien
> - Keine destruktiven Operationen

**FÃ¼r den Main Agent (Dings):**
- Spawnt den passenden Sub-Agent je nach Aufgabe
> - Modelle: `gpt-5.2-codex`, `gpt-5.3-codex`, `gemini-3-pro-preview`, `gemini-3-flash-preview`:
- Schreibe dem Subagenten: "Lese `/home/maxim/.openclaw/workspace/projects/dings-trader/docs/TRAINING_ROADMAP.md` und mache den nÃ¤chsten Zwischenschritt aus `## ðŸ“‹ TODO Liste`."
- Ãœberwacht den Fortschritt
- Integriert Ergebnisse
- Bei Bedarf: Browser-Automation fÃ¼r Google Colab
- Fertige zwischen Tasks in diesem Dokument mit einem grÃ¼nen Haken (âœ…) markieren

### Google Colab Integration

1. **Lokale Entwicklung** (Codex Sub-Agent):
   - Code wird lokal geschrieben und getestet
   - `.ipynb` Notebooks werden generiert

2. **Transfer zu Colab** (Main Agent oder manuell):
   - Code wird in Google Colab kopiert
   - A100 GPU fÃ¼r Training genutzt
   - Ergebnisse werden zurÃ¼ckgespielt

### Iterativer Prozess

Dieses Projekt wird **nicht in einem Rutsch** umgesetzt:
- Modulare Entwicklung (Data-Loader â†’ Model â†’ Training â†’ Evaluation)
- Mehrere Iterationen und AnlÃ¤ufe
- Kontinuierliches Refinement
- in kleinen zwischen Schritten bearbeiten

---

## ðŸ§  Zwei-Modell-Architektur

**Ziel:** Ein System aus zwei kooperierenden ML-Modellen

1. **Preis-Vorhersage-Modell** (Predictor)
   - Vorhersage zukÃ¼nftiger Kursbewegungen
   - Output: Erwartete Preis-Range / Richtung

2. **Entscheidungs-Modell** (Actor/Trader)
   - Tradiert auf Basis der Vorhersagen
   - Output: Long/Short/Flat + Position-Size

**Training:** Beide Modelle Ã¼ber Google Colab (A100 GPU)

---

## ðŸ“‹ TODO Liste


### ðŸ”„ Statusâ€‘Update (2026-02-10) â€” strict fail-fast (keine Mock-Fallbacks)

**Code/Contracts âœ… (implementiert + gehÃ¤rtet):**
- [x] Step 4 Dataset Builder vorhanden (`build_dataset.py`, slot_15m, missing flags, funding mapping)
- [x] Step 5 Feature Engine strict (Scaler-Fit nur 2019â€“2023, keine Dummy-Scaler)
- [x] Step 6 Env Fixes (slot_15m mapping, funding, missing/NaN handling)
- [x] Step 8 Forecast Pipeline Fixes (Inputs aus `features.parquet`, Output `forecast_0..34`)
- [x] Step 9 PPO Merge strict (Forecast required, fail-fast; legacy rename `fc_feat_*` â†’ `forecast_*` ok)

**Training/Artefakte â¬œ (noch offen / blocked):**
- [ ] Step 3 Multiâ€‘Year Binance Daten (2019+) laden (sonst Lookback512/Buffer800 & Scaler-Fit unmÃ¶glich)
- [ ] Step 8 PatchTST **trainieren** â†’ `models/forecast_model.pt`
- [ ] Step 8 Precompute (erfordert `forecast_model.pt`) â†’ `data_processed/forecast_features.parquet`
- [ ] Step 9 PPO **trainieren** â†’ Policy Artefakte (z.B. `ppo_policy.zip`)

"Smoke-Run mit 4â€‘Tage Mock-Daten" war nur historisch; seit strict-mode bricht das (gewollt) ab.



# Roter Faden v5 (final) â€” BTCUSDT Perp Bot (Forecast + PPO) mit 15m Decision / 3m Intrabar + Loss/Feedback + Trade-Limits

---

## Schritt 0 â€” Fixe Spezifikation (nicht mehr anfassen)

### Instrument
- BTCUSDT Perp (USDT-M), isolated

### Taktung
- Decision timeframe: **15m**
- Intrabar-Simulation timeframe (Backtest/Offline): **3m** (5Ã—3m pro 15m)
- Lookback fÃ¼rs Modell: **512Ã—15m â‰ˆ 5,3 Tage**
- Buffer fÃ¼rs Bootstrapping + Longterm Stats: **800Ã—15m â‰ˆ 8,3 Tage**

### Limits / Risk
- Max Hold: **48h** â‡’ **192** Decision-Steps (15m) pro Trade
- Max Exposure gleichzeitig offen: **10% Equity**
- Max gleichzeitig offene Positionen (Lots): **10**
- Leverage: **1â€“10**
- **Long/Short Exclusion (v1, enforced):** **NIE long und short gleichzeitig**  
  â†’ Wenn bereits Long-Lots offen sind, wird Short-Open geblockt (und umgekehrt). Das reduziert Chaos + Overtrading.

### Workspace / Datenablage
âœ… **ERLEDIGT:**
- **Alle Daten, Modelle, Code und Artefakte** werden in `/dings-trader/TraderHimSelf/` abgelegt
- Dies ist das zentrale Arbeitsverzeichnis fÃ¼r alle Sub-Agents
- Struktur: `data/`, `models/`, `notebooks/`, `logs/`, `checkpoints/`

### Fees
- Taker: **0.0006** (Market)
- Maker: **0.0002** (spÃ¤ter, nicht v1)
- v1 nutzt Market-Entries/Exits â‡’ taker only

### SL/TP Regel
- SL/TP als ATR-Multiples gesetzt
- Intrabar Trigger:
  - Wenn SL und TP innerhalb derselben 3m-Bar getroffen: **SL-first** (konservativ)

---

## Schritt 1 â€” Setup (Training vs Execution)

### 1A) Training in Google Colab (A100)
- Install: torch, stable-baselines3, gymnasium, numpy, pandas, pyarrow
- Projektstruktur:
  - data_raw/
  - data_processed/
  - features/
  - env/
  - forecast/
  - policy/
  - eval/
  - runs/
  - live/

### 1B) Bot Execution auf deinem PC (Ubuntu VM empfohlen)
- Inference alle 15m: Feature â†’ Forecast â†’ PPO â†’ Risk â†’ Action
- Kein High-End Rechner nÃ¶tig (Training ist der teure Teil)

**Artefakte (mÃ¼ssen exportiert werden)**
- scaler.pkl (Normalisierung)
- forecast_model.pt (PatchTST)
- ppo_policy.zip (Stable-Baselines3 PPO)
- config.json (Konstanten + Feature-Order + Obs-Order + Action-Mapping)

---

## Schritt 2 â€” Data Contract (Training = Live)

**CandleRecord**
- open_time_ms, open, high, low, close, volume

**FundingRecord**
- time_ms, funding_rate

**Regel**
- Backtest/Shadow/Demo/Live nutzen exakt dasselbe Schema + denselben Feature-Code.

---

## Schritt 3 â€” Datenquellen (historisch vs live) âš ï¸ (blocked: Multiâ€‘Year Historie fehlt aktuell)

### 3A) Historie (Training/Backtest) = Binance (Multi-Year mÃ¶glich)
- OHLCV 15m: 2019 â†’ heute
- OHLCV 3m: 2019 â†’ heute (oder soweit verfÃ¼gbar)
- Speichern:
  - data_raw/btcusdt_15m.parquet
  - data_raw/btcusdt_3m.parquet

### 3B) Live/Demo/Execution = Bitget (Parity zum echten Handel)
- Candles + Funding live von Bitget
- API-Key nÃ¶tig erst fÃ¼r Demo/Live Trading (nicht fÃ¼r reines Market Data)

---

## Schritt 4 â€” Dataset Builder (einmal sauber bauen)

Script: build_dataset.py

1) Load OHLCV 15m + 3m
2) Align:
   - jeder 15m Slot hat idealerweise exakt 5Ã—3m Subbars
   - missing Subbars markieren (keine Future-Leaks)
3) Funding-Serie:
   - Funding auf Timeline mappen (step-wise gehalten)
4) Save:
   - data_processed/aligned_15m.parquet
   - data_processed/aligned_3m.parquet
   - data_processed/funding.parquet

Checks:
- keine Time-Travel Bugs
- konsistente Zeitzonen/timestamps

---

## Schritt 5 â€” Feature Engine (fixe Feature-Liste + Reihenfolge) âœ…

**Prinzip**
- Eine Feature-Funktion compute_features(buf_15m) fÃ¼r Backtest UND Live.
- buf_15m LÃ¤nge: 800 (fÃ¼r 7d stats). Model-Lookback bleibt 512.
- **Implementiert in:** `TraderHimSelf/feature_engine.py`
- **Scaler:** `data_processed/scaler.pkl` (Fit auf 2019-2023)
- **Unit-Test:** Parity-Check (historisch vs live)

### 5.1 Core Feature Vector (fest, Reihenfolge!)

#### A) Returns & Range (Basis)
1. ret_1 = log(close_t / close_{t-1})
2. ret_4 (1h) = log(close_t / close_{t-4})
3. ret_16 (4h) = log(close_t / close_{t-16})
4. ret_48 (12h) = log(close_t / close_{t-48})
5. hl_range_pct = (high - low) / close
6. oc_range_pct = (close - open) / open

#### B) VolatilitÃ¤t & ATR
7.  vol_16  = rolling_std(ret_1, 16)   (~4h)
8.  vol_96  = rolling_std(ret_1, 96)   (~1d)
9.  vol_672 = rolling_std(ret_1, 672)  (~7d)  (aus buf_15m >= 672)
10. atr_14  = ATR(14)

#### C) Trend / Mean Reversion
11. ema_20_dist  = (close - EMA20)/EMA20
12. ema_50_dist  = (close - EMA50)/EMA50
13. ema_200_dist = (close - EMA200)/EMA200
14. ema_20_slope = (EMA20 - EMA20_prev)/EMA20_prev
15. ema_50_slope = (EMA50 - EMA50_prev)/EMA50_prev
16. adx_14       = ADX(14)

#### D) Momentum
17. rsi_14
18. macd        = EMA12 - EMA26
19. macd_signal = EMA(macd, 9)
20. macd_hist   = macd - macd_signal

#### E) Volume (robust)
21. vol_log  = log(1 + volume)
22. vol_z_96 = zscore(vol_log, 96)

#### F) Zeit-Features
23. hour_sin
24. hour_cos
25. dow_sin
26. dow_cos

#### G) Funding Features
27. funding_rate_now
28. time_to_next_funding_steps (in 15m steps, capped 0..32)

Core Features Dimension: 28

### 5.2 Normalisierung (fest)
- Fit StandardScaler nur auf Train (2019â€“2023)
- Apply identisch auf Val/Test/Live
- Save scaler.pkl
- Live niemals neu fitten

### 5.3 Parity Unit-Test (Pflicht)
- historische Candles als Stream simulieren
- Feature-Vektor muss identisch zu offline gerechnetem Vektor sein (float tolerance)

---

## Schritt 6 â€” Trading Environment (15m Decision + 3m Intrabar + Multi-Position bis 10 Lots) âœ…

File: env/perp_env.py (Gymnasium Env)

### 6.1 Portfolio-State (fest)
âœ… **Implementiert:** `TraderHimSelf/env/perp_env.py`
- equity
- open_positions: Liste von Positions-Lots (0..10), jedes Lot enthÃ¤lt:
  - side âˆˆ {long, short}
  - margin_used
  - leverage L
  - notional = margin_used * L
  - entry_price
  - qty = notional / entry_price
  - sl_price, tp_price
  - open_time_ms
  - time_in_trade_steps_15m

**Konservativ v1:**
- Wenn open_positions nicht leer:
  - Neue Position darf nur in derselben Richtung geÃ¶ffnet werden
  - Gegenseitiges Hedging wird geblockt (reduziert Overtrading/Chaos)

### 6.2 uPnL (USDT-M linear) pro Lot
âœ… **Implementiert**

### 6.3 Fees (taker only v1)
âœ… **Implementiert** (0.0006)

### 6.4 Funding (event-basiert)
âœ… **Implementiert**

### 6.5 Slippage (konservativ, gegen dich)
âœ… **Implementiert** (ATR-basiert)

### 6.6 Liquidation (isolated, konservativer Proxy)
âœ… **Implementiert**

### 6.7 SL/TP setzen (ATR-Multiples) pro Lot
âœ… **Implementiert**

### 6.8 Intrabar Simulation innerhalb 15m (5Ã—3m)
âœ… **Implementiert** (SL-first)

---

## Schritt 7 â€” Risk Manager Wrapper (hardcoded, vor ML!) + Overtrading-Controls âœ…

File: env/risk_manager.py

### 7.1 Hard Caps (fest)
âœ… **Implementiert:** `TraderHimSelf/env/risk_manager.py`
1) **Exposure cap**
- exposure_open_margin = Summe(margin_used aller offenen Lots)
- available_exposure = 0.10*equity - exposure_open_margin
- clamp new_margin_used zu available_exposure
- wenn available_exposure <= 0 â†’ force flat (keine neue Position)

2) **Max offene Positionen**
- max_open_positions = 10
- wenn len(open_positions) >= 10 â†’ force flat (keine neue Position)

3) **Leverage clamp**
- L âˆˆ [1, 10]

4) **SL/TP clamp**
- sl_mult âˆˆ [0.5, 3.0]
- tp_mult âˆˆ [0.5, 6.0]
- tp_mult >= sl_mult

5) **No-hedge rule (v1, konservativ)**
- wenn offene Lots existieren:
  - wenn action direction â‰  Richtung der offenen Lots â†’ force flat

### 7.2 Soft Controls (damit er nicht 1000 Trades ballert)
âœ… **Implementiert** (Entry Penalty: 0.0002 * equity)

---

## Schritt 8 â€” Forecast Modell (PatchTST) + Forecast Feature Block + Forecast Loss (Supervised) âœ…

File: forecast/train_patchtst.py

### 8.1 Input
âœ… **Implementiert:** `TraderHimSelf/forecast/train_patchtst.py`
- Lookback = 512
- Input channels: 28 Core Features (normalisiert)

### 8.2 Targets (multi-horizon)
âœ… **Implementiert** (q10, q50, q90 fÃ¼r 1h, 4h, 12h, 24h, 48h)

### 8.3 Forecast Feature Block (fix)
âœ… **Implementiert** (35 Dimensions: Horizon Block, Path Block, Curve Stats)

### 8.4 Forecast Loss (Pinball / Quantile Loss)
âœ… **Implementiert** (Horizon weights: w_4=1.0, w_16=1.0, w_48=0.8, w_96=0.6, w_192=0.4)

### 8.5 Forecast Evaluation (Val/Test)
âœ… **Vorbereitet**

### 8.6 Precompute Pflicht
âœ… **CLI-Modus implementiert** (`precompute`)
- Output: `data_processed/forecast_features.parquet` (Spalten `forecast_0..34`, NaNâ€‘Padding fÃ¼r Lookback)
- **Strict:** erfordert `models/forecast_model.pt` (sonst Abbruch) â€” erst `train`, dann `precompute`
- Forecast weights anschlieÃŸend **freezen** (fÃ¼r PPO Training)

---

## Schritt 9 â€” PPO Policy Training + PPO Loss / Credit Assignment (RL) âœ…

File: policy/train_ppo.py
âœ… **Implementiert:** `TraderHimSelf/policy/train_ppo.py`
âš ï¸ Trainingâ€‘Artefakte (z.B. `ppo_policy.zip`) entstehen erst nach echtem PPOâ€‘Training.

### 9.1 Testen aller Bausteine (System-Check) âœ…
- Alles nach Roadmap gemacht? âœ…
- Kommunikation zwischen Modulen prÃ¼fen (Data -> Feature -> Env -> Policy) âœ…
- Schnittstellen-Validierung âœ…
- Logik-Review âœ…
- Bericht erstellt: `TraderHimSelf/system_check_report.md` âœ…

### 9.2 Bug-Hunting (Sub-Agent Audit) âœ…
- Neue Sub-Agent Instanz spawnen âœ…
- Codebase nach logischen Fehlern, Edge-Cases und Performance-Bottlenecks scannen âœ…
- **Status:** Audit abgeschlossen, 3 kritische Fehler in `perp_env.py` gefunden. Bericht in `audit_report_9.2.md`.

### 9.2.1 Bug-Fixing (Refactoring) âœ…
- Behebung des Time-Travel-Bugs in `perp_env.py`. âœ…
- Korrektur der Liquidation-Logik. âœ…
- Performance-Optimierung der Intrabar-Simulation (O(1) Zugriff). âœ…

### 9.3 Planung: Umzug nach Google Colab âœ…
- [x] Plan + Artefakt-Matrix: `docs/COLAB_MIGRATION_PLAN.md`
- [x] Entscheidung: Variante A (empfohlen) = **git clone im Colab**
- [x] `download_binance_data.py` Pfade relativ/parametrisierbar gemacht (`--data-dir`, `--start-date`, `--end-date`, `--symbol`)

### 9.4 Umzug vorbereiten (Notebooks + BÃ¼ndelung) âœ…
- [x] Notebook-Kette angelegt: `00_setup.ipynb` â€¦ `07_eval.ipynb`
- [x] `00_setup.ipynb`: Drive mount + Store-Ordner + Symlinks (`data_raw`, `data_processed`, `models`, `logs`, `runs`, `checkpoints`)
- [x] Notebook-Zellen rufen die bestehenden Scripts auf (kein doppelter Code)
- [x] Pro Step klare Status-Ausgabe `OK:` / `ERROR:` + Logs unter `logs/colab/*.log`
- [x] Finale Report-Zelle in `07_eval.ipynb` (`REPORT_START` / `REPORT_END` via `report_status.py`)

### 9.5 Anleitung schreiben (User Guide) âœ…
- [x] Step-by-step Guide: `docs/COLAB_USER_GUIDE.md`

### 9.6 Fokus Stop & Manueller Umzug (User Action) â¬œ
- [ ] Fokus-Mode fÃ¼r alle Agenten beenden (wenn wir wirklich rÃ¼bergehen)
- [ ] **User fÃ¼hrt Umzug durch:** nach `docs/COLAB_USER_GUIDE.md`
- [ ] Erster Start des Trainings in der Cloud

---

## Schritt 10 â€” Evaluation (Walk-forward)

Splits:
- Train: 2019â€“2023
- Val:   2024
- Test:  2025

KPIs:
- net PnL after costs
- max drawdown
- liquidation count
- fee share
- exposure time
- avg open positions (soll klein sein)
- trades per week (soll klein sein)

Baselines:
- flat always
- EMA trend + ATR SL/TP

---

## Schritt 11 â€” Warmstart / Bootstrapping (fest)

Beim Bot-Start (Shadow/Demo/Live identisch):
1) Ziehe mindestens **800Ã—15m** Candles (Buffer) (mindestens 512, aber Ziel 800)
2) Rechne Features:
   - Model Input: letzte 512 Candles
   - Longterm Stats: aus 800er Buffer (z.B. vol_672)
3) Lade scaler + forecast + ppo
4) Erst wenn Buffer voll & Candle final valid â†’ Decision Loop starten

Gap Handling:
- Wenn Candles fehlen (Bot offline):
  - Missing nachziehen
  - wenn nicht mÃ¶glich: force flat bis Buffer wieder konsistent

**Wichtig:** Bootstrapping ist live schnell machbar:
- 800Ã—15m â‰ˆ 8,3 Tage. Das wird einmalig nachgeladen, danach lÃ¤uftâ€™s mit Live-Candles weiter.

---

## Schritt 12 â€” Shadow Live (kein Trading, kein Key nÃ¶tig)

File: live/shadow_runner.py
- alle 15m (close + 3s):
  1) neue 15m Candle holen, Buffer append
  2) Features + Forecast + PPO Action
  3) RiskManager check
  4) nur loggen, keine Orders

Optional:
- 3m Candles der letzten 15m holen fÃ¼r Debug/Monitoring

---

## Schritt 13 â€” Demo Live (Bitget Demo API-Key nÃ¶tig)

- Bootstrapping wie Schritt 11
- Policy â†’ Risk â†’ Demo Orders + SL/TP setzen
- Outcomes loggen
- Demo ist Pflicht-Gate, bevor echtes Geld Ã¼berhaupt angefasst wird

---

## Schritt 14 â€” Live scharf schalten (echtes Geld)

Nur wenn:
- Shadow stabil
- Demo stabil
- KPIs okay

Dann:
- Subaccount + kleines Kapital (empfohlen)
- Trade-Key ohne Withdraw/Transfer
- Start mit kleiner Exposure (1â€“2%), langsam hoch bis 10%
- (spÃ¤ter) VPS mit fixer IP fÃ¼r IP-Whitelist

---

## Was du JETZT programmieren lÃ¤sst (exakte Reihenfolge)
1) build_dataset.py (15m+3m, Alignment, Funding Schema)
2) feature_engine.py (28 Core Features + scaler + Parity Test)
3) perp_env.py (15m decision + 3m intrabar + SL-first + Multi-positions bis 10)
4) risk_manager.py (Exposure cap + max 10 positions + no-hedge + entry penalty)
5) PatchTST training + forecast precompute (35 Features + Pinball Loss)
6) PPO training (Obs dim 72, reward shaping inkl. entry penalty)
7) Evaluation (walk-forward + baseline)
8) bootstrapping + gap handling
9) shadow live
10) demo live
11) live


